{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dj2rEVV7-Ppm",
   "metadata": {
    "id": "dj2rEVV7-Ppm"
   },
   "source": [
    "# Spam Filter using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6012c",
   "metadata": {
    "id": "e7c6012c"
   },
   "source": [
    "You are given a collection of SMS text messages in `sms.csv` as a tab separated CSV file. The first column of this file tells whether the message is a spam or not spam and the second column gives the message. Assume that this dataset is labelled correctly as spam or not spam. We  will use this dataset as the training data to build a spam filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76096a",
   "metadata": {
    "id": "ae76096a"
   },
   "source": [
    "(a) Analyze the dataset and identify top ten spam words and top ten non-spam words  and their frequency counts. Make sure that you first remove articles (\"a\", \"and\", \"the\") and <=4 letter propositions (\"for\", \"off\", \"in\", \"from\" and so on).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4692a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 spam words are\n",
      "[('call', 348), ('free', 219), ('txt', 146), ('mobile', 123), ('claim', 113), ('stop', 109), ('text', 105), ('reply', 96), ('www', 96), ('prize', 90)]\n",
      "Top 10 non spam words are\n",
      "[('lt', 315), ('gt', 315), ('get', 298), ('ok', 281), ('go', 244), ('call', 235), ('got', 230), ('know', 230), ('good', 229), ('come', 229)]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "file  = open('sms.csv')         #opening the file\n",
    "csvreader = csv.reader(file, delimiter='\\t')   #using the delimiter as tab\n",
    "rows = []            #storing the info of each row in this list\n",
    "spamID = []          #storing whether any message is spam or not\n",
    "spamInd = []         #indexes of spam messages\n",
    "nspamInd = []        #indexes of not spam messages\n",
    "words = []           #storing all the words\n",
    "unique = []          #storing all the unique words\n",
    "spamwords = []       #storing all the spam words\n",
    "spamunique = []      #storing all the unique words\n",
    "nspamwords = []      #storing all the non spam words\n",
    "nspamunique = []     #storing all the non spam unique words\n",
    "stopwords = ['', 'â', \"you\", \"a\", \"and\", \"the\", 'u','ur','4','1','2','i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'you', 'your', 'yours', 'he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'they', 'them', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'wouldn']\n",
    "for row in csvreader:\n",
    "    rows.append(row)\n",
    "for row in rows:\n",
    "    row[1] = row[1].lower()\n",
    "    temp = re.split(r'\\W+', row[1] )\n",
    "    for word in temp:     #storing the words\n",
    "        if word not in stopwords:\n",
    "            words.append(word)\n",
    "    for word in temp:     #storing all the unique words\n",
    "        if word not in stopwords:\n",
    "            if word not in unique:\n",
    "                unique.append(word)\n",
    "    if row[0] == \"spam\":           #0 indicates spam\n",
    "        spamID.append(0)\n",
    "        spamInd.append(rows.index(row))\n",
    "        for word in temp:\n",
    "            if word not in stopwords:\n",
    "                spamwords.append(word)\n",
    "        for word in temp:\n",
    "            if word not in stopwords:\n",
    "                if word not in spamunique:\n",
    "                    spamunique.append(word)\n",
    "    else:                          #1 indiactes not spam\n",
    "        spamID.append(1)\n",
    "        nspamInd.append(rows.index(row))\n",
    "        for word in temp:\n",
    "            if word not in stopwords:\n",
    "                nspamwords.append(word)\n",
    "        for word in temp:\n",
    "            if word not in stopwords:\n",
    "                if word not in nspamunique:\n",
    "                    nspamunique.append(word)\n",
    "\n",
    "#print(spamwords)\n",
    "topspam = Counter(spamwords).most_common(10)     #getting the top 10 spamwords\n",
    "topnspam = Counter(nspamwords).most_common(10)   #getting the top 10 non spam words\n",
    "print(\"Top 10 spam words are\")\n",
    "print(topspam)\n",
    "print(\"Top 10 non spam words are\")\n",
    "print(topnspam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9fef6",
   "metadata": {
    "id": "dfc9fef6"
   },
   "source": [
    "(b) Let `W` be the random variable denoting a word and `T` be the random variable denoting a message's type (spam or non-spam). For each of the words `w` (spam or non-spam), estimate the likelihood probabilities (aka the conditional probabilities) `Pr(W = w | T=spam)` and `Pr(W=w | T=non-spam)` as two separate functions. Note  that in order to compute these likelihoods this, you need to compute how many times `w` appears in the corpus (spam or not spam) and the total number of words (including duplicates) in that corpus. If a word does not occur at all, then assign it a non-zero yet small probability fixed suitably. Note that the likelihoods `Pr(w | spam)` and `Pr(w | non-spam)` have to be estimated after suitably removing articles and propositions as done in (a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b24dc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pspam(w):           #probability for spam for each word\n",
    "    if w in spamwords:\n",
    "        return len(spamwords)/len(unique)\n",
    "    else:\n",
    "        return 1/len(words)\n",
    "def Pnotspam(w):           #probability for not spam for each word\n",
    "    if w in nspamwords:\n",
    "        return len(nspamwords)/len(unique)\n",
    "    else:\n",
    "        return 1/len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066d1ef",
   "metadata": {
    "id": "1066d1ef"
   },
   "source": [
    "(c) Let `M` be the random variable denoting a message (consisting of multiple words). Using the likelihood probabilities calculated in (b), implement a classifier that takes in a new SMS message `m=w1 w2 ... wi` and checks if it is spam or not using the naive Bayes' assumption. That is, compute `P(T=spam | M=m)` and `P(T=non-spam | M=m)` assuming that `P(m | spam) = P(w1 | spam) x P(w2 | spam) x ... x P(wi | spam)` and use this computation to decide if `m` is spam or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dd434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "def classifier(M):\n",
    "    msgw = re.split(r'\\W+', M)\n",
    "    ps = 1\n",
    "    pns = 1\n",
    "    for i in range(len(msgw)):\n",
    "        ps *= Pspam(msgw[i])\n",
    "        pns *= Pnotspam(msgw[i])\n",
    "    pSpam = len(spamInd)/len(spamID)       #based on number of spam messages\n",
    "    pNotSpam = 1 - pSpam\n",
    "    pSpGivenM = pSpam*(ps/((ps*pSpam)+(pns*pNotSpam)))          #bayes rule\n",
    "    pNotSpGivenM = pNotSpam*(pns/((ps*pSpam)+(pns*pNotSpam)))\n",
    "    if pSpGivenM > pNotSpGivenM:   #printing the result\n",
    "        print(\"spam\")\n",
    "    else:\n",
    "        print(\"not spam\")\n",
    "classifier(\"You are a winner U have been specially selected 2 receive Â£1000 or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810910p/min (18+) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0d429",
   "metadata": {
    "id": "3db0d429"
   },
   "source": [
    "(d) Test your classifier against 4-5 SMS messages (spam as well as non-spam) that you have received in your mobile phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95920f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n",
      "not spam\n",
      "not spam\n",
      "spam\n",
      "not spam\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append(\"Dear customer, As an appreciation for being an HDFC Bank customer, you can take advantage of new Credit Card without documentation.Check here: hdfcbk.io/a/oBXL4GVw\")\n",
    "messages.append(\"Congrats ! Get annual savings worth Rs. 12000 on your pre-approved Bajaj Finserv RBL Bank Credit card. Avail now v.db1.in/a7XZ40 SRIBALAJI\")\n",
    "messages.append(\"Congratulation! You are eligible for IDFC Bank Credit Card LIFE TIME FREE With limit upto 5 Lakhs.T&C Applied. Apply Now v.db1.in/9XXMyP SRIBALJI\")\n",
    "messages.append(\"Dear User, You’ve earned RummyCircle 100% Welcome Bonus upto Rs 3000* on Specials. Click on https://t.jio/winnings-RUMCPS to claim your coupon! T&C Team JioCoupon\")\n",
    "messages.append(\"Register free for AAKASH ANTHE for upto 100% Scholarship & Win a trip to NASA* Eligibility: Class 7 - 12 Online Exam from Home! Apply@ bit.ly/3QHRhR2 MOTACH\")\n",
    "for i in range(5):\n",
    "    classifier(messages[i])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
